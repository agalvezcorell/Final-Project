{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "from scipy.fftpack import fft\n",
    "import pydub\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataSetAudios(nombre):\n",
    "    lista = []\n",
    "    listafin = []\n",
    "    for a in range(1,7):\n",
    "        audio = AudioSegment.from_file(f'../audios/{nombre}{a}.m4a', format='mp4')\n",
    "        lista.append(audio)\n",
    "    for a in lista:\n",
    "        array = a.get_array_of_samples()[:528320]\n",
    "        four = abs(fft(array))\n",
    "        listafin.append(four)\n",
    "    \n",
    "    return listafin        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convInt(x):\n",
    "    x = int(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = \"Afecto\"\n",
    "ale = \"Alegria\"\n",
    "enf = \"Enfado\"\n",
    "trs = \"Tristeza\"\n",
    "afecto = dataSetAudios(af)\n",
    "alegria = dataSetAudios(ale)\n",
    "enfado = dataSetAudios(enf)\n",
    "tristeza = dataSetAudios(trs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "alegriad = {\"transformada\": [a for a in alegria], \"etiqueta\": 1}\n",
    "enfadod = {\"transformada\": [a for a in enfado], \"etiqueta\": 2}\n",
    "tristezad = {\"transformada\": [a for a in tristeza], \"etiqueta\":3}\n",
    "afectod = {\"transformada\": [a for a in afecto], \"etiqueta\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "todos = [alegriad,enfadod,tristezad,afectod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haceDf(elemento):\n",
    "    temp = []\n",
    "    for a in elemento:\n",
    "        df = pd.DataFrame(elemento)\n",
    "        temp.append(df)\n",
    "    return pd.concat(temp).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = pd.DataFrame(alegriad)\n",
    "tr= pd.DataFrame(tristezad)\n",
    "en = pd.DataFrame(enfadod)\n",
    "af = pd.DataFrame(afectod)\n",
    "todos = pd.concat([al,tr,en,af]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate((np.vstack(al.transformada),np.vstack(tr.transformada),np.vstack(en.transformada),np.vstack(af.transformada)))\n",
    "y=np.concatenate((al.etiqueta,tr.etiqueta,en.etiqueta,af.etiqueta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 528320)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 528320)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 200)\n",
    "gbc = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc.fit(X_train, y_train)\n",
    "y_pred = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(gbc, '../modelos/model_gbcx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)\n",
    "h_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(rfc, '../modelos/model_rfcx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "accrandomf = accuracy_score(y_test, y_pred)\n",
    "accgradient = accuracy_score(y_test,h_pred)\n",
    "print(accrandomf, accgradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesaUnAudio(audio):\n",
    "    lista = []\n",
    "    array = audio.get_array_of_samples()[:528320]\n",
    "    print(len(array))\n",
    "    four = abs(fft(array))\n",
    "    lista.append(four)\n",
    "    return np.vstack(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with sr.Microphone() as source:\n",
    "    print(\"Expresa algo\")\n",
    "    audio = r.record(source, duration=13)\n",
    "    print(\"Grabaci√≥n terminada. Procesando...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open(\"audio.wav\", \"wb\") as f:\n",
    "        f.write(audio.get_wav_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "audio = AudioSegment.from_file(f'audio.wav', format='mp4')\n",
    "prueba = procesaUnAudio(audio)\n",
    "predigo = gbc.predict(prueba)\n",
    "predigo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
